{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tercera parte.  Recomendacion basada en filtrado colaborativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grupo 16**\n",
    "- Daniela Alejandra Cordova Porta\n",
    "- David Bugoi\n",
    "- Erik Karlgren Domercq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tercera parte utilizaremos la librería SURPRISE Se puede consultar la documentacion en http://surpriselib.com/\n",
    "\n",
    "Para instalarla: `conda install -c conda-forge scikit-surprise` o `pip install numpy pip install scikit-surprise`.\n",
    "\n",
    "La librería SurPRISE (<i>Simple Python RecommendatIon System Engine</i>) tiene algoritmos de predición de ratings incluidos: <i>baseline algorithms</i>, <i>neighborhood methods</i>, <i>matrix factorization-based</i> (SVD, PMF, SVD++, NMF) y otros. También tiene predefinidas las medidas de similitud más comunes sobre vectores (<i>cosine</i>, MSD, pearson…) Una de las cosas más útiles es que proporciona herramientas para evaluar, analizar y comparar el rendimiento de distintos algoritmos. Lo que vamos a hacer en esta parte de la práctica es probar varios procedimientos de evaluación cruzada midiendo datos sobre errores entre el valor real (conocido) y la predicción del recomendador. Las siglas corresponden a las siguientes medidas:\n",
    "\n",
    "- MAE: _Mean Absolute Error_\n",
    "- RMSE: _Root mean square error_ (RMSE)\n",
    "- MSE: mean square error is defined as the expected value of the square of the difference between the estimator and the parameter. -square root of the mean square error.\n",
    "\n",
    "Vamos a ejecutar algunos recomendadores y evaluarlos para poder comentar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9316  0.9358  0.9376  0.9398  0.9338  0.9357  0.0028  \n",
      "MAE (testset)     0.7347  0.7388  0.7369  0.7410  0.7368  0.7377  0.0021  \n",
      "Fit time          3.65    3.64    3.66    3.62    3.74    3.66    0.04    \n",
      "Test time         0.14    0.10    0.13    0.11    0.18    0.13    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93163571, 0.93575979, 0.93756398, 0.93980909, 0.9338424 ]),\n",
       " 'test_mae': array([0.73472964, 0.73875508, 0.73693932, 0.74104354, 0.73683877]),\n",
       " 'fit_time': (3.6474547386169434,\n",
       "  3.63614821434021,\n",
       "  3.6558492183685303,\n",
       "  3.6166446208953857,\n",
       "  3.7376270294189453),\n",
       " 'test_time': (0.1361072063446045,\n",
       "  0.10495305061340332,\n",
       "  0.1336040496826172,\n",
       "  0.11096739768981934,\n",
       "  0.1831073760986328)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ejemplo getting started de la documentación de SURPRISE\n",
    "##http://surpriselib.com/\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de funciones\n",
    "Usaremos estas funciones para evaluar varios algoritmos de recomendación. La función `get_results` escribirá sobre el fichero `results_user_cf.csv` añadiéndole texto al final. Queremos asegurarnos de que el fichero exista y esté vacío (salvo por una cabecera) antes de llamar a dicha función por primera vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el fichero en el mismo directorio que está guardado este notebook y le añadimos una cabecera\n",
    "f = open(\"results_user_cf.csv\", 'w')\n",
    "f.write(\"K,Algorithm,Precision,Recall,F1\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation extracted from surprise: \n",
    "# https://surprise.readthedocs.io/en/stable/FAQ.html#how-to-compute-precision-k-and-recall-k\n",
    "def measures_at_k(predictions, k, th_recom, th_relev):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    onehits = dict()\n",
    "    mrr = dict()\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        \n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= th_relev) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= th_recom) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= th_relev) and (est >= th_recom))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "       \n",
    "        \n",
    "    return precisions, recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(precision, recall):\n",
    "    \"\"\"\n",
    "        Funcion que calcula el f1 (media armónica) en funcion de precision y recall\n",
    "    \"\"\"\n",
    "    denominador = precision + recall\n",
    "    \n",
    "    if denominador == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall) / denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda los resultados de las recomendaciones en el fichero \"results_user_cf.csv\"\n",
    "def get_results(recommendations, k, knn):\n",
    "    \"\"\"\n",
    "        Function to get the measures results \n",
    "    \"\"\"\n",
    "    # threshold = 4 --> solo se tienen en cuenta peliculas que hayan \n",
    "    # sido puntuadas con 4 o 5 estrellas\n",
    "    precisions, recalls  = measures_at_k(recommendations, k, th_recom=4, th_relev=1)\n",
    "    \n",
    "    # Measures can then be averaged over all users\n",
    "    precision_result = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall_result = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    # Media armónica  \n",
    "    f1_result = f1(precision_result, recall_result)\n",
    "    # En este archivo se volcarán los resultados de las métricas. Tiene que existir. \n",
    "    f = open(\"results_user_cf.csv\", 'a')\n",
    "    #f = open(\"C:/hlocal/results_user_cf.csv\", 'a')\n",
    "    f.write(str(k) + ',' + knn + \",\" + str(precision_result) + ',' + str(recall_result) + ',' +  str(f1_result) +  '\\n') \n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de los algoritmos de recomendación\n",
    "Hemos cargado antes los datos de movieLens para 100K con la siguiente función:\n",
    "```python\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "```\n",
    "Ahora creamos 2 conjuntos de datos: los datos de entrenamiento (`training_set`) y los de evaluación (`evaluation_set`). Cada uno contendrá la mitad de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, evaluation_set = train_test_split(data, test_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a emplear varios algoritmos de recomendación y guardar sus resultados en el fichero `results_user_cf.csv`.\n",
    "### KNN Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_algorithm = KNNBasic(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `training_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x226e497f6a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_algorithm.fit(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `evaluation_set` y obtengo las predicciones en las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommendation_algorithm.test(evaluation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0043  1.0006  0.9993  1.0014  0.9999  1.0011  0.0017  \n",
      "MAE (testset)     0.7972  0.7906  0.7910  0.7889  0.7940  0.7924  0.0029  \n",
      "Fit time          1.66    1.67    1.70    1.67    1.68    1.68    0.01    \n",
      "Test time         3.73    3.42    3.45    3.76    3.56    3.58    0.14    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.00429252, 1.00055043, 0.99929365, 1.00144132, 0.99990104]),\n",
       " 'test_mae': array([0.79724739, 0.7906253 , 0.79104514, 0.78889743, 0.79403654]),\n",
       " 'fit_time': (1.6617188453674316,\n",
       "  1.6731925010681152,\n",
       "  1.700601577758789,\n",
       "  1.6683690547943115,\n",
       "  1.6756517887115479),\n",
       " 'test_time': (3.732666254043579,\n",
       "  3.42401123046875,\n",
       "  3.447269916534424,\n",
       "  3.756788730621338,\n",
       "  3.555835485458374)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(recommendation_algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN With Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_algorithm = KNNWithMeans(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `training_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x226e4a52b50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_algorithm.fit(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `evaluation_set` y obtengo las predicciones en las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommendation_algorithm.test(evaluation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_withmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9469  0.9418  0.9389  0.9331  0.9319  0.9385  0.0055  \n",
      "MAE (testset)     0.7380  0.7338  0.7342  0.7291  0.7255  0.7321  0.0043  \n",
      "Fit time          1.69    1.70    1.74    1.72    1.76    1.72    0.03    \n",
      "Test time         3.67    3.69    3.85    3.85    3.89    3.79    0.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94687422, 0.94176123, 0.93885707, 0.93314358, 0.9318679 ]),\n",
       " 'test_mae': array([0.73796376, 0.73380236, 0.73422473, 0.72914897, 0.72548756]),\n",
       " 'fit_time': (1.6928811073303223,\n",
       "  1.6972360610961914,\n",
       "  1.74053955078125,\n",
       "  1.7221970558166504,\n",
       "  1.758854627609253),\n",
       " 'test_time': (3.674858808517456,\n",
       "  3.691965341567993,\n",
       "  3.8530361652374268,\n",
       "  3.8516950607299805,\n",
       "  3.8879013061523438)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(recommendation_algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN With Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_algorithm = KNNWithZScore(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `training_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithZScore at 0x226e4a521f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_algorithm.fit(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `evaluation_set` y obtengo las predicciones en las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommendation_algorithm.test(evaluation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_withzscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9477  0.9345  0.9376  0.9409  0.9311  0.9383  0.0057  \n",
      "MAE (testset)     0.7346  0.7271  0.7274  0.7328  0.7272  0.7298  0.0032  \n",
      "Fit time          1.79    1.76    1.83    1.85    1.75    1.79    0.04    \n",
      "Test time         4.01    4.34    4.23    3.98    4.00    4.11    0.15    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94770425, 0.93445182, 0.9375827 , 0.94085838, 0.9310527 ]),\n",
       " 'test_mae': array([0.73461205, 0.72713066, 0.72741664, 0.73277199, 0.72717478]),\n",
       " 'fit_time': (1.7854182720184326,\n",
       "  1.763239860534668,\n",
       "  1.8270072937011719,\n",
       "  1.845022439956665,\n",
       "  1.7492692470550537),\n",
       " 'test_time': (4.013169765472412,\n",
       "  4.343783617019653,\n",
       "  4.233802556991577,\n",
       "  3.9780144691467285,\n",
       "  3.997918128967285)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(recommendation_algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_algorithm = KNNBaseline(k=100, sim_options={'name': 'pearson_baseline', 'user_based': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `training_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x226fe489160>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_algorithm.fit(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico el algoritmo sobre el `evaluation_set` y obtengo las predicciones en las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = recommendation_algorithm.test(evaluation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "for k in range(K):\n",
    "    get_results(recommendations, k+1, \"knn_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9210  0.9178  0.9267  0.9090  0.9311  0.9211  0.0076  \n",
      "MAE (testset)     0.7205  0.7186  0.7278  0.7138  0.7288  0.7219  0.0057  \n",
      "Fit time          1.67    1.65    1.67    1.68    1.66    1.67    0.01    \n",
      "Test time         4.52    4.56    4.52    4.63    4.31    4.51    0.10    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92098501, 0.91784152, 0.92669751, 0.90904049, 0.9311187 ]),\n",
       " 'test_mae': array([0.7204744 , 0.7185902 , 0.7277729 , 0.71383533, 0.72880122]),\n",
       " 'fit_time': (1.674551010131836,\n",
       "  1.6541361808776855,\n",
       "  1.6705143451690674,\n",
       "  1.6819627285003662,\n",
       "  1.6604681015014648),\n",
       " 'test_time': (4.517550945281982,\n",
       "  4.559155225753784,\n",
       "  4.5216851234436035,\n",
       "  4.627239465713501,\n",
       "  4.314043283462524)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(recommendation_algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:  se pide ejecutar, comprender y escribir comentarios razonados sobre la evaluación de distintos recomendadores.\n",
    "    \n",
    "Prueba otros algoritmos de predicción de ratings basados en la estimación de los vecinos más próximos y realiza evaluaciones de su comportamiento. Comenta los resultados.\n",
    "Puedes consultar la documentación en https://surprise.readthedocs.io/en/stable/knn_inspired.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE y RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto `MAE` como `RMSE` expresan el error de predicción promedio y los valores mientras más bajos son, mejores. La diferencia entre estas dos es que como RMSE consiste en elevar los errores al cuadrado antes de promediarlos, le otorga un peso relativamente alto a los errores grandes que se obtienen. \n",
    "\n",
    "\n",
    "Si analizamos los valores que dieron para cada algoritmo, desde SVD hasta KNN Baseline; podemos observar que en el orden: KNN Basic, SVD, KNN With Means, KNN With Z-Score, KNN Baseline va mejorando la media de error. Esto quiere decir que la predicción del recomendador difiere cada vez menos con los valores reales. \n",
    "\n",
    "Otro punto a observar es que `KNN Basic` en comparación con los otros algoritmos en el error `RMSE` crece con ritmo distinto a los demás, subiendo por encima del 1. Esto quiere decir que tiene errores más grandes en comparación con los demás algoritmos.\n",
    "\n",
    "En resumen; si queremos un recomendador que nos devuelva unos k vecinos que se adapten mejor a las valoraciones reales que tendrá el usuario, la mejor opción según este análisis es el `KNN Baseline`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall y Precisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos recomendar al usuario los N elementos primeros en lugar de todos a un usuario. Por ello, el recall y precisión lo envaluamos sobre un k donde k es un número entero definido por el usuario para que coincida el top N de recomendaciones principales. Entonces la precisón en k es la proporción de elementos recomendados en el conjunto top k relevantes. \n",
    "\n",
    "Si k= 10 en un top-10 de recomendados y la precisión es un 80%, esto siginfica que el 80% de las recomendaciones que hago son relevantes para el usuario.\n",
    "\n",
    "El Recall en k es la proporción de elementos relevantes que se encuentran en el top_k de recomendaciones.\n",
    "\n",
    "Si k=10 en un top-10 y el recall es 40%, quiere decir que el 40% del número total de elementos relevantes aparecen en los primeros resultados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 nos ayuda a entender el balance entre el recall y precisión, su máximo valor es 1 y quiere decir que todas las predicciones son recomendaciones correctas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vemos el fichero `results_user_cf.csv`, observamos que la precisión de cada algoritmo no varía en función del valor de K, pero el recall sí que aumenta al incrementarse K. Consecuentemente, la media armónica también aumenta y conseguimos mejores recomendaciones.\n",
    "\n",
    "A la hora de comparar los algoritmos entre sí el que consigue mejor precisión es KNNBasic seguido de, en orden decreciente de precisión, KNN Baseline, KNN With Z-Score y KNN With Means. Es decir, KNN Basic es el algoritmo que mayor proporción de items relevantes consigue de los items que recomienda. No obstante, KNN Basic consigue el peor recall de todos los algoritmos que hemos probado, por lo que es el que menos items recomienda de los items relevantes. El resto tienen recalls parecidos para el mismo valor de K.\n",
    "\n",
    "Para comparar todos los algoritmos es preferible usar la media armónica de la precisión y el recall pues cuando se incrementa la precisión decrece el recall y viceversa, así que buscamos un \"equilibrio\" óptimo. En este aspecto podemos observar que KNN Baseline es el algoritmo que mejor se comporta de todos, seguido de KNN With Means y KNN With Z-Score, y siendo KNN Basic el peor de todos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analicemos un ejemplo específico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir que como nuestro k en todos los algoritmos está en un rango máximo de 10, estamos analizando el top_10 relevantes. (El valor por defecto es k=100).\n",
    "\n",
    "En el caso del `knn_baseline` obtiene por ejemplo:\n",
    "\n",
    "    - Precisión: 0.917285259809119\n",
    "    - Recall: 0.190821119640963\n",
    "    - F1: 0.315921654370031\n",
    "    \n",
    "Es decir, nuestro recomendador hace un 91,7% de recomendaciones relevantes y un 19% de las recomendaciones relevantes están en primeros resultados. Esto quiere decir que tenemos un buen balance, no todas las recomendaciones tienen que estar de primeras y aunque no da 100% relevantes, hay una gran cantidad de ellas y en su mayoría en los primeros puestos. \n",
    "\n",
    "En el caso del `knn_basic` obtiene por ejemplo:\n",
    "\n",
    "    - Precisión: 0.946977730646871\n",
    "    - Recall: 0.0354763013581841\n",
    "    - F1: 0.0683905124463774\n",
    "    \n",
    "El recomendador hace un 94.6% de recomendaciones relevantes y solo un 3.5% están en los primeros resultados. No hay muy buen balance. De que me sirve tener buenas recomendaciones si no las muestro de primero aunque sea unas pocas. Conocemos que las personas prefieren ver primero recomendaciones que sí les gusten, no ir a ver la siguientes. Por eso esto no tiene un buen equilibrio. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
