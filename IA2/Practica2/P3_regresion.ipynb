{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "patent-amazon",
   "metadata": {},
   "source": [
    "# Práctica 2: Aprendizaje automático\n",
    "\n",
    "__Fecha de entrega: 16 de mayo de 2021__\n",
    "\n",
    "El objetivo de esta práctica es aplicar los distintos algoritmos de aprendizaje automático disponibles en la scikit-learn [sklearn](https://scikit-learn.org/stable/) sobre varios conjuntos de datos y aprender a interpretar los resultados obtenidos. La práctica consta de 3 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n",
    "\n",
    "Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n",
    "\n",
    "Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-floor",
   "metadata": {},
   "source": [
    "# Parte 3: Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-bruce",
   "metadata": {},
   "source": [
    "__Número de grupo: XX__\n",
    "\n",
    "__Nombres de los estudiantes: XXX y XXX__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-sympathy",
   "metadata": {},
   "source": [
    "En este notebook trabajaremos con una colección de datos de alquileres de Airbnb en Amsterdam. El objetivo de este problema es entrenar una red neuronal capaz de predecir el precio del alojamiento a partir de un conjunto de características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-biotechnology",
   "metadata": {},
   "source": [
    "## 1) Descripción de los datos\n",
    "\n",
    "Carga el fichero de datos `airbnb.csv` en un dataframe. Describe el conjunto de datos y trata de interpretar el significado de cada una de las variables. Estudia la distribución de precios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-attitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "upper-subject",
   "metadata": {},
   "source": [
    "## 2) Selección de variables\n",
    "\n",
    "Calcula los coeficientes de correlación de Pearson entre la variable de salida y el resto de variables. Crea un nuevo dataframe que contenga el precio y, además, las variables que estén relacionadas con él por un valor de correlacción de al menos 0.2 (de forma directa o inversa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-photograph",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-world",
   "metadata": {},
   "source": [
    "## 3) Normalización\n",
    "\n",
    "Decide si debes o no normalizar los datos. En caso afirmativo elige razonadamente entre escalarlos o estandarizarlos.\n",
    "\n",
    "Si decides escalar los datos deberás crear dos `scalers` distintos, uno para el array con la descripción de los pisos y otro para el array con el precio. Lo hacemos de este modo porque así podremos desescalar las predicciones más fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-intro",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "political-french",
   "metadata": {},
   "source": [
    "## 4) Entrenamiento y selección\n",
    "\n",
    "Crea dos redes neuronales de tipo Perceptrón Multicapa:\n",
    "- La primera con una capa oculta de 200 neuronas\n",
    "- La segunda con dos capas ocultas cada una de 100 neuronas\n",
    "\n",
    "Pinta la curva de aprendizaje para cada red variando el parámetro `alpha` que controla el coeficiente de regularización L2 y determina el valor óptimo usando validación cruzada. Asegúrate de que no salen warnings indicando que no se ha alcanzado la convergencia durante el entrenamiento (basta con poner un número de max_iter suficientemente grande).\n",
    "\n",
    "¿Alguna de las dos redes domina a la otra? ¿Por qué crees que se producen las diferencias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-solution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "laden-asbestos",
   "metadata": {},
   "source": [
    "## 5) Medición del error\n",
    "\n",
    "Elige la mejor configuración del apartado anterior y usa la función `cross_val_predict` para realizar una predicción del valor de todos los establecimientos usando validación cruzada. ¿Cuál es el error medio del modelo en euros? ¿Crees que el modelo es suficientemente bueno?\n",
    "\n",
    "Pinta la distribución del error en euros y el diagrama de dispersión de la predicción frente al valor real. ¿El modelo comete los mismos tipos de errores en establecimientos de distintos precios? ¿Por qué crees que se producen esos errores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-delicious",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
